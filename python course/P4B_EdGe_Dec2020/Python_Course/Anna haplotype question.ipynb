{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "everyone\n"
     ]
    }
   ],
   "source": [
    "#can put if else statement into a list to make it more comprehensive\n",
    "#e.g. [a_numbeer*2 for a number in some_list] ##where some_list is another list which you want to edit \n",
    "\n",
    "print(\"\"\"Hello\n",
    "everyone\"\"\") ##triple quotes let you put multiple lines in a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First a very useful function. There's nothing quite like this in itertools so I'll\n",
    "# write my own.\n",
    "# Note I'd normally use 'yield' here but we haven't covered that so I'll use\n",
    "# an accumulator list (named res) instead.\n",
    "\n",
    "def batches(iter_in, batch_size, include_stub=True, slide=0):\n",
    "    \"\"\"\n",
    "    Given a list (or indeed any iterable), split the list into batches\n",
    "    If the last batch is too small, we can decide whether to include this remaining stub.\n",
    "    slide=0 means produce discrete chunks.\n",
    "    \"\"\"\n",
    "    # List for the final result\n",
    "    res = []\n",
    "    \n",
    "    if slide == 0 or slide > batch_size:\n",
    "        slide = batch_size #if slide not specified then slide = batch size so are discrete slides\n",
    "        \n",
    "    this_batch = [] # accumulator for sub-lists\n",
    "    stub = False    # is there a stub to return?\n",
    "    for i in iter_in:\n",
    "        this_batch.append(i)\n",
    "        stub = True\n",
    "        if len(this_batch) == batch_size:\n",
    "            res.append(this_batch)\n",
    "            stub = False\n",
    "            this_batch = this_batch[slide:]\n",
    "    if stub and include_stub:\n",
    "        res.append(this_batch)\n",
    "        \n",
    "    # return everything\n",
    "    return res\n",
    "        \n",
    "# Look it works! Note that these assertions would normally go into a separate unit test file.\n",
    "# See https://docs.python.org/3/library/unittest.html for details, but note you really\n",
    "# need to know about defining classes first.\n",
    "assert batches([],  1) == []\n",
    "\n",
    "assert batches(\"ABCDEF\",  3, include_stub=True ) == [['A','B','C'],['D','E','F']]#batches of 3 specified\n",
    "assert batches(\"ABCDEF\",  3, include_stub=False) == [['A','B','C'],['D','E','F']]\n",
    "assert batches(\"ABCDEFG\", 3, include_stub=True ) == [['A','B','C'],['D','E','F'],['G']]#include stub = true keeps the extra ones \n",
    "assert batches(\"ABCDEFG\", 3, include_stub=False) == [['A','B','C'],['D','E','F']]\n",
    "assert batches(range(3),  1, include_stub=True ) == [[0],[1],[2]]\n",
    "assert batches(range(3),  1, include_stub=False) == [[0],[1],[2]]\n",
    "\n",
    "assert batches(\"ABCDE\",  3, include_stub=True,  slide=1) == [['A','B','C'],['B','C','D'],['C','D','E']]#batches of 3 with sliding window \n",
    "assert batches(\"ABCDE\",  3, include_stub=False, slide=1) == [['A','B','C'],['B','C','D'],['C','D','E']]\n",
    "assert batches(\"ABC\",    4, include_stub=True,  slide=1) == [['A','B','C']]\n",
    "assert batches(\"ABC\",    4, include_stub=False, slide=1) == []\n",
    "assert batches(range(3), 1, include_stub=True,  slide=1) == [[0],[1],[2]]\n",
    "assert batches(range(3), 1, include_stub=False, slide=1) == [[0],[1],[2]]\n",
    "\n",
    "assert batches(\"ABCDE\",  4, include_stub=True,  slide=3) == [['A','B','C','D'],['D','E']]\n",
    "assert batches(\"ABCDE\",  4, include_stub=False, slide=3) == [['A','B','C','D']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's load the data from the files.\n",
    "# Many people would say this could be better done with Pandas,\n",
    "# but for now let's use regular Python (see below for Pandas).\n",
    "\n",
    "def load_froh_2019():\n",
    "    \"\"\"Load old_files/Froh_2019.txt\n",
    "       We only want the IID column, so return this as a set.\n",
    "    \"\"\"\n",
    "    file_obj = open(\"old_files/Froh_2019.txt\")\n",
    "    res = set() # A set is just like a dict with no values.\n",
    "    \n",
    "    # If (and only if) you are splitting the line on whitespace -- .split()\n",
    "    # you can dispense with the .rstrip('\\n')\n",
    "    headers = next(file_obj).split()  # Grab the header\n",
    "    for l in file_obj:\n",
    "        res.add(l.split()[headers.index('IID')])\n",
    "    \n",
    "    return res\n",
    "    \n",
    "# The file has 3047 lines so that should be 3046 individuals\n",
    "all_froh_2019 = load_froh_2019()\n",
    "assert len(all_froh_2019) == 3046\n",
    "assert \"ABS08\" in all_froh_2019\n",
    "\n",
    "def load_snp_names(k):\n",
    "    \"\"\"Load the AlphaPeel_files/all_chr/Deer_AlphaPeel_marker_file_chr{k}.txt\n",
    "       We just want a list of all the names, so column 1.\n",
    "    \"\"\"\n",
    "    file_obj = open(f\"AlphaPeel_files/all_chr/Deer_AlphaPeel_marker_file_chr{k}.txt\")\n",
    "    res = []\n",
    "    \n",
    "    headers = next(file_obj).split()  # Grab the header\n",
    "    for l in file_obj:\n",
    "        res.append(l.split()[headers.index('SNP.name')])\n",
    "    \n",
    "    return res\n",
    "    \n",
    "# Chromo 10 has 561 data lines in the file.\n",
    "all_snp_names_chr10 = load_snp_names(\"10\")\n",
    "assert len(all_snp_names_chr10) == 561\n",
    "assert all_snp_names_chr10[0] == \"cela1_red_25_1069003\"\n",
    "assert all_snp_names_chr10[-1] == \"cela1_red_25_42782721\"\n",
    "\n",
    "def load_alphapeel_chr(k):\n",
    "    \"\"\"Load the chromosome matrix for chromosome k.\n",
    "       Each individual has two haplotypes, so we'll get back a dict \n",
    "           {id: [hap1, hap2]}\n",
    "       Where hap1 and hap2 are strings (because why not?).\n",
    "    \"\"\"\n",
    "    file_obj = open(f\"AlphaPeel_files/all_chr/AlphaPeel_out_chr{k}.called_phase.0.95\")\n",
    "    res = {} #returning dictionary\n",
    "    \n",
    "    for aline in file_obj:\n",
    "        splitline = aline.split()\n",
    "        res.setdefault(splitline[0],[]).append(''.join(splitline[1:]))#mushes 1010 into a string\n",
    "    return res\n",
    "\n",
    "# Chromo 10 has 12826 lines so we should get 12826 / 2 entries.\n",
    "# All entries should be 561 characters long (ie. len(all_snp_names_chr10))\n",
    "all_alphapeel_chr10 = load_alphapeel_chr(\"10\")\n",
    "assert len(all_alphapeel_chr10) == 12826 / 2\n",
    "assert all_alphapeel_chr10['ABA14'][0].startswith('11110111')\n",
    "assert all_alphapeel_chr10['ABA16'][1].endswith('10011110')\n",
    "assert all([len(l) == 561 for p in all_alphapeel_chr10.values() for l in p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas code. Alternative file reading with Pandas.\n",
    "# Maybe we can plot the numbers in this file with seaborn??\n",
    "import pandas as pd\n",
    "\n",
    "def load_froh_2019_pandas():\n",
    "    \"\"\"Load old_files/Froh_2019.txt\n",
    "       This uses Pandas to load the whole table. I don't use this in the code\n",
    "       below, but I could do. It returns the same as the non-pandas code.\n",
    "    \"\"\"\n",
    "    froh_table = pd.read_table(\"old_files/Froh_2019.txt\")  #pd = pandas dataframe\n",
    "    return set(froh_table['IID'])\n",
    "\n",
    "# Should be exactly as before. Which it is.\n",
    "assert len(load_froh_2019_pandas()) == 3046\n",
    "assert load_froh_2019_pandas() == load_froh_2019()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#counter builds a dictionary to count the number of times something occurs in a list\n",
    "# Function to calculate the diversity given a list of haplotypes,\n",
    "# where a haplotype is just a string.\n",
    "def calc_div(haplos):\n",
    "    \"\"\" The formula is:\n",
    "           sum( nh(nh-1) for h in distinct haplos )\n",
    "           -----------------------------------\n",
    "               len(haplos) * len(haplos) - 1\n",
    "        Where nh is the number of times a given haplotype occurs \n",
    "        in the list \n",
    "    \"\"\"\n",
    "    # First thing to do is count all the haplos\n",
    "    # Counter is a special type of dict which does this in one go...\n",
    "    hcounts = Counter(haplos)\n",
    "    # Then sum over the counts like so...\n",
    "    #top = sum([ hcounts[h] * (hcounts[h] - 1) for h in haplos ])#list comprehension \n",
    "    top = sum([ n * (n - 1) for n in hcounts.values() ])\n",
    "    bottom = len(haplos) * (len(haplos) - 1)\n",
    "    \n",
    "    return 1 - (top / bottom)\n",
    "\n",
    "\n",
    "# The calc_div function should work on any list of things\n",
    "assert calc_div(\"AAAAAA\") == 0.0  # Not diverse\n",
    "assert calc_div(\"ABCDEF\") == 1.0  # Super diverse\n",
    "assert calc_div(\"AAADEF\") == 0.8  # Medium diverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the data, let's generate some results. I extracted just the numbers for chr10 from\n",
    "the previous results.\n",
    "\n",
    "```bash\n",
    "$ tr -d $'\\r' < AlphaPeel_files/all_chr/Genomewide_hap_div_tbl.txt | \\\n",
    "    egrep -e '^haplo' -e '\\b10$' \\\n",
    "    > AlphaPeel_files/chr10_hap_div_tbl.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given chromosome matrix, get a list of chunks, where each\n",
    "# chunk is a list of haplotypes (as \"01010...\" strings)\n",
    "def get_chunks_for_chromo(chr_dict, batch_size=10, slide=0):\n",
    "    \"\"\"Re-format the output of load_alphapeel_chr into \n",
    "       a list of lists of haplos, where each entry in the main list is a\n",
    "       batch of ten haplotype calls (columns) from the input file.\n",
    "    \"\"\"\n",
    "    # Transform the data structure \n",
    "    all_chunks = []\n",
    "    for hap_pair in chr_dict.values():\n",
    "        for hap in hap_pair:\n",
    "            # hap is now a string of 0s and 1s\n",
    "            for n, hap_chunk in enumerate(batches( hap, \n",
    "                                                   batch_size = batch_size, \n",
    "                                                   slide = slide, \n",
    "                                                   include_stub = False )):\n",
    "                if len(all_chunks) == n:\n",
    "                    # If the list is too short, extend it.\n",
    "                    all_chunks.append([])\n",
    "                # Add this to the corresponding list\n",
    "                all_chunks[n].append(''.join(hap_chunk))\n",
    "                \n",
    "    return all_chunks\n",
    "\n",
    "# Again a test with some very minimal data\n",
    "fake_chr_dict = { 'i1': [ '11111111',\n",
    "                          '19111111' ],\n",
    "                  'i2': [ '00000000',\n",
    "                          '09000000' ],\n",
    "                  'i3': [ '01010101',\n",
    "                          '01010101' ], }\n",
    "assert get_chunks_for_chromo(fake_chr_dict, 3) == [ ['111', '191', '000', '090', '010', '010'],\n",
    "                                                    ['111', '111', '000', '000', '101', '101'] ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2939 samples from the matrix\n",
      "After filtering on 3046 old samples, 2939 are left.\n",
      "-\n",
      "0.919218697063114 -- 0.9192186970631141 -- -0.0000000000\n",
      "0.856987662458537 -- 0.8569876624585366 -- 0.0000000000\n",
      "0.896464083867627 -- 0.8964640838676265 -- 0.0000000000\n",
      "0.917073423365657 -- 0.9170734233656569 -- 0.0000000000\n",
      "0.905695590230731 -- 0.9056955902307311 -- -0.0000000000\n",
      "0.930430980098905 -- 0.9304309800989053 -- -0.0000000000\n",
      "0.937756964252841 -- 0.9377569642528407 -- 0.0000000000\n",
      "0.90870599656563 -- 0.9087059965656301 -- -0.0000000000\n",
      "0.893955833048005 -- 0.8939558330480045 -- 0.0000000000\n",
      "0.87710936239318 -- 0.87710936239318 -- 0.0000000000\n",
      "0.897538404747131 -- 0.8975384047471308 -- 0.0000000000\n",
      "0.907280871066946 -- 0.9072808710669462 -- -0.0000000000\n",
      "0.895654727471177 -- 0.895654727471177 -- 0.0000000000\n",
      "0.916601333339217 -- 0.916601333339217 -- 0.0000000000\n",
      "0.907187939856013 -- 0.9071879398560134 -- -0.0000000000\n",
      "0.942580933998487 -- 0.9425809339984865 -- 0.0000000000\n",
      "0.913482598356507 -- 0.9134825983565068 -- 0.0000000000\n",
      "0.893625285351115 -- 0.8936252853511147 -- 0.0000000000\n",
      "0.901371600768238 -- 0.9013716007682384 -- -0.0000000000\n",
      "0.930145531797341 -- 0.9301455317973409 -- 0.0000000000\n",
      "0.91387679790931 -- 0.9138767979093096 -- 0.0000000000\n",
      "0.899643982570758 -- 0.8996439825707581 -- -0.0000000000\n",
      "0.9143846810928 -- 0.9143846810927999 -- 0.0000000000\n",
      "0.936536317712756 -- 0.9365363177127561 -- -0.0000000000\n",
      "0.920507281204327 -- 0.9205072812043273 -- -0.0000000000\n",
      "0.900980106744299 -- 0.9009801067442988 -- 0.0000000000\n",
      "0.928649243603012 -- 0.9286492436030118 -- 0.0000000000\n",
      "0.884203137494152 -- 0.8842031374941518 -- 0.0000000000\n",
      "0.905816374407206 -- 0.9058163744072063 -- -0.0000000000\n",
      "0.929784222716578 -- 0.9297842227165783 -- -0.0000000000\n",
      "0.915527767630811 -- 0.9155277676308108 -- 0.0000000000\n",
      "0.886837000662353 -- 0.886837000662353 -- 0.0000000000\n",
      "0.848976669032997 -- 0.8489766690329965 -- 0.0000000000\n",
      "0.890944726578624 -- 0.8909447265786238 -- 0.0000000000\n",
      "0.848378695801401 -- 0.8483786958014006 -- 0.0000000000\n",
      "0.853124362887547 -- 0.8531243628875473 -- -0.0000000000\n",
      "0.904214273479092 -- 0.9042142734790924 -- -0.0000000000\n",
      "0.870177996286369 -- 0.8701779962863687 -- 0.0000000000\n",
      "0.847357634584734 -- 0.8473576345847339 -- 0.0000000000\n",
      "0.877497716749044 -- 0.877497716749044 -- 0.0000000000\n",
      "0.879398951440035 -- 0.8793989514400353 -- -0.0000000000\n",
      "0.910153707148055 -- 0.910153707148055 -- 0.0000000000\n",
      "0.879041913600492 -- 0.8790419136004919 -- 0.0000000000\n",
      "0.87662743818721 -- 0.8766274381872101 -- -0.0000000000\n",
      "0.885413285995165 -- 0.885413285995165 -- 0.0000000000\n",
      "0.85693206208007 -- 0.8569320620800703 -- -0.0000000000\n",
      "0.869377036403775 -- 0.8693770364037753 -- -0.0000000000\n",
      "0.862360851873175 -- 0.8623608518731749 -- 0.0000000000\n",
      "0.863895792465774 -- 0.8638957924657744 -- -0.0000000000\n",
      "0.865405258140718 -- 0.8654052581407182 -- -0.0000000000\n",
      "0.892650427895235 -- 0.8926504278952353 -- -0.0000000000\n",
      "0.855426954470398 -- 0.8554269544703983 -- -0.0000000000\n",
      "0.862792351318262 -- 0.8627923513182623 -- -0.0000000000\n",
      "0.876419954655887 -- 0.8764199546558872 -- -0.0000000000\n",
      "0.879163893399615 -- 0.8791638933996151 -- -0.0000000000\n",
      "0.858658664330933 -- 0.8586586643309331 -- -0.0000000000\n"
     ]
    }
   ],
   "source": [
    "# Putting all together. Just chr10 for now...\n",
    "chromo = \"10\"\n",
    "\n",
    "# Load up haplo matrix for this chromo (AlphaPeel_out_chr{k}.called_phase.0.95)\n",
    "all_alphapeel_chrK = load_alphapeel_chr(chromo)\n",
    "\n",
    "# Filter the inputs to just the samples from Froh_2019.txt\n",
    "# Note that not all these samples are in the matrix.\n",
    "all_froh_2019 = load_froh_2019()\n",
    "print(f\"Got {len(all_alphapeel_chr10)} samples from the matrix\")\n",
    "for k in list(all_alphapeel_chrK):\n",
    "    if k not in all_froh_2019:\n",
    "        del all_alphapeel_chrK[k]\n",
    "print(f\"After filtering on {len(all_froh_2019)} old samples, {len(all_alphapeel_chrK)} are left.\")\n",
    "print(\"-\")\n",
    "\n",
    "# Chunk-ify the haplotype calls\n",
    "all_chunks_chrK = get_chunks_for_chromo(all_alphapeel_chrK)\n",
    "\n",
    "# From the above shenanigans we have the all_chunks_chr10 list of lists.\n",
    "# All chunks should be the same length, ie. double the size of all_alphapeel_chr10\n",
    "# And for this chromosome there should be 56 chunks\n",
    "\n",
    "# Formally check the numbers we know for chr10...\n",
    "assert len(all_alphapeel_chrK) == 2939\n",
    "assert all([len(chunk) == (2939 * 2) for chunk in all_chunks_chrK])\n",
    "if chromo == \"10\":\n",
    "    assert len(all_chunks_chrK) == 56\n",
    "# yup!\n",
    "\n",
    "# Load the numbers that R gave previously\n",
    "ghdt_file_obj = open(\"AlphaPeel_files/all_chr/Genomewide_hap_div_tbl.txt\")\n",
    "all_rvals_chrK = [ float(ls[0]) for ls in \n",
    "                   [ line.split() for line in ghdt_file_obj ]\n",
    "                   if ls[2] == chromo ]\n",
    "if chromo == \"10\":\n",
    "    # For chromo 10 we expect this many\n",
    "    assert len(all_rvals_chrK) == 56\n",
    "\n",
    "# Now get the diversity (from calc_div()) for each of those 56 chunks...\n",
    "for n, chunk in enumerate(all_chunks_chrK):\n",
    "    old_div_from_r = all_rvals_chrK[n]\n",
    "    \n",
    "    # This calculates the diversity directly...\n",
    "    #div_for_chunk = calc_div(chunk)\n",
    "    \n",
    "    # But hang on we want the diversity excluding all the 9's\n",
    "    # Could also use a regex to filter for only /^[01]+$/\n",
    "    div_for_chunk = calc_div([c for c in chunk if not '9' in c])#any chunk thats got a 9 in it get discarded\n",
    "    \n",
    "    # Check the difference between what we got and what R said.\n",
    "    difference = old_div_from_r - div_for_chunk\n",
    "    print(f\"{old_div_from_r} -- {div_for_chunk} -- {difference:.10f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
